{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè≠ Session 5 Lab: The GenAI File Factory\n",
    "**Objective:** Move beyond \"Chat\" and use LLMs to generate structured artifacts (Docs, Code, Data, Slides).\n",
    "\n",
    "**Prerequisites:**\n",
    "1. **Ollama** running locally (`ollama serve`)\n",
    "2. Model pulled: `ollama pull llama3.2`\n",
    "3. **Pandoc** installed on your OS (`sudo apt install pandoc` or Windows installer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Pandoc version:\n",
      "pandoc 3.8.2.1\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Check if Pandoc is installed\n",
    "print(\"Checking Pandoc version:\")\n",
    "!pandoc --version | head -n 1\n",
    "\n",
    "MODEL=\"llama3.2:latest\"\n",
    "#MODEL=\"gemma3:1b\"\n",
    "#MODEL=\"gemma3:270m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def query_llm(prompt, model=MODEL):\n",
    "    \"\"\"Sends a prompt to the local Ollama instance.\"\"\"\n",
    "    print(f\"ü§ñ Asking {model}...\")\n",
    "    response = ollama.chat(model=model, messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "def extract_code_block(text, language=None):\n",
    "    \"\"\"\n",
    "    Extracts content inside ```markdown or ```python blocks.\n",
    "    Handles variations like '```markdown ' (trailing space) or different newlines.\n",
    "    \"\"\"\n",
    "    # Pattern explanation:\n",
    "    # ```         -> Start of block\n",
    "    # [^\\n]* -> Matches language name and any extra spaces until end of line\n",
    "    # \\n          -> Matches the newline after the language name\n",
    "    # (.*?)       -> Captures the actual content (non-greedy)\n",
    "    # \\n?         -> Matches optional newline before closing\n",
    "    # ```         -> End of block\n",
    "    pattern = r\"```[^\\n]*\\n(.*?)\\n?```\"\n",
    "\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[0].strip()\n",
    "\n",
    "    # Fallback: If no blocks found, try to strip just the markdown quotes if present\n",
    "    # This handles cases where the LLM might output ```markdown content ``` (one line)\n",
    "    return text.replace(\"```markdown\", \"\").replace(\"```python\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Document Generation (Markdown -> DOCX / PDF)\n",
    "We will ask Llama 3.2 to write a structured **Project Charter** in Markdown, then convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking llama3.2:latest...\n",
      "‚úÖ Markdown file saved: project_charter.md\n",
      "# Project Charter for PlantDoctor AI Mobile App\n",
      "\n",
      "## Project Title\n",
      "### PlantDoctor: Revolutionizing Urban Gardening with AI-Powered Insights\n",
      "\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "PlantDoctor is a cutting-edge AI mob...[truncated]\n"
     ]
    }
   ],
   "source": [
    "prompt_doc = \"\"\"\n",
    "You are a Senior Project Manager.\n",
    "Write a Project Charter for a new AI Mobile App called 'PlantDoctor'.\n",
    "Use Markdown formatting.\n",
    "Include these Headers (H1, H2):\n",
    "- Project Title\n",
    "- Executive Summary\n",
    "- Objectives (Bullet points)\n",
    "- Key Stakeholders (Table)\n",
    "- Risks\n",
    "\n",
    "Output ONLY the markdown code block.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Generate\n",
    "raw_doc = query_llm(prompt_doc)\n",
    "clean_doc = extract_code_block(raw_doc)\n",
    "\n",
    "# 2. Save to .md\n",
    "with open(\"project_charter.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_doc)\n",
    "\n",
    "print(\"‚úÖ Markdown file saved: project_charter.md\")\n",
    "print(clean_doc[:200] + \"...[truncated]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Converted to DOCX\n",
      "üåê Converted to HTML (for preview)\n"
     ]
    }
   ],
   "source": [
    "# 3. Convert using Pandoc\n",
    "# Convert to Word\n",
    "!pandoc project_charter.md -o project_charter.docx\n",
    "print(\"üìÑ Converted to DOCX\")\n",
    "\n",
    "# Convert to PDF (Requires LaTeX, fallback to HTML if not installed)\n",
    "# !pandoc project_charter.md -o project_charter.pdf\n",
    "# OR convert to HTML first for easy viewing\n",
    "!pandoc project_charter.md -o project_charter.html\n",
    "print(\"üåê Converted to HTML (for preview)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Using a Word Template (Reference Doc)\n",
    "To make the document look professional (corporate colors/fonts), we use a `--reference-doc`.\n",
    "*Note: Ensure you have a 'template.docx' in the folder. If not, this step uses default styling.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Created STYLED Word document using template.docx\n"
     ]
    }
   ],
   "source": [
    "# Check if user has a template, otherwise warn\n",
    "if os.path.exists(\"../../../data/timbrado.docx\"):\n",
    "    !pandoc project_charter.md --reference-doc=\"../../../data/timbrado.docx\" -o project_charter_styled.docx\n",
    "    print(\"üé® Created STYLED Word document using template.docx\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No 'template.docx' found. Please create a blank Word doc with your custom styles and name it 'template.docx' to test this feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Web Page Generation (HTML + CSS + JS)\n",
    "We will ask the LLM to generate a single-file interactive dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking llama3.2:latest...\n",
      "üåç Web page saved: dashboard.html. Open this file in your browser to see the Clock and Slideshow!\n"
     ]
    }
   ],
   "source": [
    "prompt_web = \"\"\"\n",
    "Create a single HTML file that includes embedded CSS and JavaScript.\n",
    "The page should contain:\n",
    "1. A modern, dark-mode design.\n",
    "2. A live digital clock in the center that updates every second.\n",
    "3. A simple image slideshow (use placeholders like 'https://placehold.co/600x400') below the clock.\n",
    "4. A 'Toggle Theme' button to switch between dark and light mode.\n",
    "\n",
    "Output ONLY the raw HTML code block.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Generate\n",
    "raw_web = query_llm(prompt_web)\n",
    "clean_web = extract_code_block(raw_web, language=\"html\")\n",
    "\n",
    "# 2. Save\n",
    "with open(\"dashboard.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_web)\n",
    "\n",
    "print(\"üåç Web page saved: dashboard.html. Open this file in your browser to see the Clock and Slideshow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Code Generation & Execution (Python)\n",
    "We will generate Python code to perform a mathematical simulation (Approximating Pi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking llama3.2:latest...\n",
      "üêç Python script saved. Running it now...\n",
      "\n",
      "Estimated Pi: 3.13384\n",
      "Actual Pi: 3.141592653589793\n",
      "Time taken: 0.03189969062805176 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_code = \"\"\"\n",
    "Write a complete Python script to estimate the value of Pi using the Monte Carlo method.\n",
    "- Use 100,000 iterations.\n",
    "- Print the estimated value vs the actual value from the math library.\n",
    "- Do not use any input() functions (it needs to run unattended).\n",
    "Output ONLY the python code block.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Generate\n",
    "raw_code = query_llm(prompt_code)\n",
    "clean_code = extract_code_block(raw_code, language=\"python\")\n",
    "\n",
    "# 2. Save\n",
    "with open(\"calc_pi.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_code)\n",
    "\n",
    "print(\"üêç Python script saved. Running it now...\\n\")\n",
    "\n",
    "# 3. Execute the generated code\n",
    "!python calc_pi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Presentation Slides (Markdown -> PPTX)\n",
    "Pandoc can turn Markdown headings into PowerPoint slides.\n",
    "- `H1` (#) = Title Slide\n",
    "- `H2` (##) = New Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking llama3.2:latest...\n",
      "üìΩÔ∏è Presentation generated: presentation.pptx\n"
     ]
    }
   ],
   "source": [
    "prompt_slides = \"\"\"\n",
    "Generate a presentation outline about 'The Future of Generative AI' in Markdown.\n",
    "Structure it for Pandoc conversion:\n",
    "- Use '#' for the Presentation Title.\n",
    "- Use '##' for 5 distinct slides.\n",
    "- Use bullet points for content.\n",
    "\n",
    "Per slide, suggest one figure that is relevant for the content.\n",
    "Output ONLY the markdown code.\n",
    "\"\"\"\n",
    "\n",
    "raw_slides = query_llm(prompt_slides)\n",
    "clean_slides = extract_code_block(raw_slides)\n",
    "\n",
    "with open(\"presentation.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_slides)\n",
    "\n",
    "# Convert to PPTX\n",
    "!pandoc presentation.md -o presentation.pptx\n",
    "print(\"üìΩÔ∏è Presentation generated: presentation.pptx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 5. Data Engineering (CSV Generation & Excel Export)\n",
    "We will ask the LLM to generate dummy data, then we use Python to load it into Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking llama3.2:latest...\n",
      "üíæ CSV Saved.\n",
      "üìä Loaded Data: 50 rows found.\n",
      "üìà Converted to Excel: sales_report.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Category</th>\n",
       "      <th>Amount</th>\n",
       "      <th>CustomerCity</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>Mobile Phones</td>\n",
       "      <td>129.99</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>29.8977</td>\n",
       "      <td>159.8877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Gaming Laptop</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>499.99</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>114.9977</td>\n",
       "      <td>614.9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>E-book</td>\n",
       "      <td>Books</td>\n",
       "      <td>11.99</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>2.7577</td>\n",
       "      <td>14.7477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>299.99</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>68.9977</td>\n",
       "      <td>368.9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Smartwatch</td>\n",
       "      <td>Mobile Accessories</td>\n",
       "      <td>79.99</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>18.3977</td>\n",
       "      <td>98.3877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID        Date          Product            Category  Amount  \\\n",
       "0              1  2023-01-01       Smartphone       Mobile Phones  129.99   \n",
       "1              2  2023-01-02    Gaming Laptop             Laptops  499.99   \n",
       "2              3  2023-01-03           E-book               Books   11.99   \n",
       "3              4  2023-01-04  Washing Machine          Appliances  299.99   \n",
       "4              5  2023-01-05       Smartwatch  Mobile Accessories   79.99   \n",
       "\n",
       "   CustomerCity       Tax     Total  \n",
       "0       Bangkok   29.8977  159.8877  \n",
       "1     Singapore  114.9977  614.9877  \n",
       "2     Hong Kong    2.7577   14.7477  \n",
       "3  Kuala Lumpur   68.9977  368.9877  \n",
       "4        Taipei   18.3977   98.3877  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_data = \"\"\"\n",
    "Generate a CSV file with 50 rows of dummy E-commerce sales data.\n",
    "Columns: TransactionID, Date, Product, Category, Amount, CustomerCity.\n",
    "Make sure the data looks realistic.\n",
    "Output ONLY the CSV data block.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Generate\n",
    "raw_csv = query_llm(prompt_data)\n",
    "clean_csv = extract_code_block(raw_csv)\n",
    "\n",
    "# 2. Save to CSV\n",
    "with open(\"sales_data.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_csv)\n",
    "print(\"üíæ CSV Saved.\")\n",
    "\n",
    "# 3. Process with Pandas and Save to Excel\n",
    "try:\n",
    "    df = pd.read_csv(\"sales_data.csv\")\n",
    "    print(f\"üìä Loaded Data: {df.shape[0]} rows found.\")\n",
    "\n",
    "    # Simple transformation: Calculate Tax\n",
    "    if 'Amount' in df.columns:\n",
    "        df['Tax'] = df['Amount'] * 0.23\n",
    "        df['Total'] = df['Amount'] + df['Tax']\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(\"sales_report.xlsx\", index=False)\n",
    "    print(\"üìà Converted to Excel: sales_report.xlsx\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing CSV: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
